{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb85252-5b2d-47db-8650-bd80471319db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    PowerTransformer,\n",
    "    FunctionTransformer\n",
    ")\n",
    "from feature_engine.encoding import (\n",
    "\tRareLabelEncoder,\n",
    "    MeanEncoder,\n",
    "    CountFrequencyEncoder\n",
    ")\n",
    "from feature_engine.datetime import DatetimeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81017d00-d8c3-4eb9-93de-19ecb03ab7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = 'R:\\Jaydeep\\Flight-Price-Prediction'\n",
    "DATA_DIR = 'data'\n",
    "MAIN_DATASET_NAME = 'flight_price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ef1c31-303c-4d63-b4ca-874590dc6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name):\n",
    "    file_name = f'{dataset_name}.csv'\n",
    "    file_path = os.path.join(PROJECT_DIR, DATA_DIR, file_name)\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9260cb67-fb0f-4eb4-9bea-1c86daf45fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataset(MAIN_DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a6a2b7-1b5e-4df6-a956-b58bc98247f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f776ba6b-5a8e-4d5d-b361-909371b3b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae218e01-449f-48b0-b501-aba007aa6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    return df.rename(columns=str.lower)\n",
    "\n",
    "def strip_string_columns(df):\n",
    "    string_columns = df.select_dtypes(include='O').columns\n",
    "    for col in string_columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "def clean_airline_names(df):\n",
    "    df['airline'] = (\n",
    "        df['airline']\n",
    "        .str.replace(\" Premium economy\", \"\")\n",
    "        .str.replace(\" Business\", \"\")\n",
    "        .str.title()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def convert_dates(df):\n",
    "    df['date_of_journey'] = pd.to_datetime(df['date_of_journey'], dayfirst=True)\n",
    "    return df\n",
    "\n",
    "def convert_times(df):\n",
    "    df['dep_time'] =  pd.to_datetime(df['dep_time'], format='mixed').dt.time\n",
    "    df['arrival_time'] = pd.to_datetime(df['arrival_time'], format='mixed').dt.time\n",
    "    return df\n",
    "\n",
    "def convert_duration(df):\n",
    "    duration_split = df['duration'].str.split(\" \", expand=True).set_axis([\"hour\", \"minute\"], axis=1)\n",
    "    duration_split['hour'] = duration_split['hour'].str.replace(\"h\", \"\").astype(int).mul(60)\n",
    "    duration_split['minute'] = duration_split['minute'].str.replace(\"m\", \"\").fillna(\"0\").astype(int)\n",
    "    df['duration_minute'] = duration_split.sum(axis=1)\n",
    "    df = df.drop(columns=['duration'])\n",
    "    return df\n",
    "\n",
    "def convert_total_stops(df):\n",
    "    df['total_stops'] = (\n",
    "        df['total_stops']\n",
    "        .replace(\"non-stop\", \"0\")  \n",
    "        .str.replace(\" stops?\", \"\", regex=True)  \n",
    "        .pipe(lambda ser: pd.to_numeric(ser)) \n",
    "    )\n",
    "    return df\n",
    "\n",
    "def lower_additional_info(df):\n",
    "    df['additional_info'] = df['additional_info'].str.lower()\n",
    "    return df\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(index=df[df['Duration'].isin(['5m'])].index, columns=['Route'])\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "    df = clean_column_names(df)         \n",
    "    df = strip_string_columns(df)       \n",
    "    df = clean_airline_names(df)        \n",
    "    df = convert_dates(df)         \n",
    "    df = convert_times(df)             \n",
    "    df = convert_duration(df)       \n",
    "    df = convert_total_stops(df)      \n",
    "    df = lower_additional_info(df)     \n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3589698-24ac-4c61-962b-fa57fe802c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cbf411d-68f6-4b5b-99eb-0efbcffd1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['airline',\n",
    " 'date_of_journey',\n",
    " 'source',\n",
    " 'destination',\n",
    " 'dep_time',\n",
    " 'arrival_time',\n",
    " 'total_stops',\n",
    " 'additional_info',\n",
    " 'duration_minute',\n",
    " 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95165724-4055-4d5a-b15f-a3f26059bae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6693, 9) (6693,)\n",
      "(1674, 9) (1674,)\n",
      "(2092, 9) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=\"price\")\n",
    "y = df.price.copy()\n",
    "\n",
    "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd128355-6b4f-490d-b006-f74bdbcc2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    n = len(y)\n",
    "    p = X.shape[1]\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    print(f'R^2: {r2:.4f}')\n",
    "    print(f'Adjusted R^2: {adj_r2:.4f}')\n",
    "    print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6abbfa4-3a02-42f9-aad0-b0b3cc5e410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_transformer = Pipeline(steps=[\n",
    "    ('grouper', RareLabelEncoder(tol=0.1, replace_with='other', n_categories=2)),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "date_tranformer = Pipeline(steps=[\n",
    "    ('date_to_features', DatetimeFeatures(features_to_extract=['month', 'day_of_week', 'day_of_year'], yearfirst=True, format='mixed')),\n",
    "    ('min_max_scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "location_transformer = Pipeline(steps=[\n",
    "    ('grouper', RareLabelEncoder(tol=0.1, replace_with='other', n_categories=2)),\n",
    "    ('mean_encoder', MeanEncoder()),\n",
    "    ('power_transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "def is_north(X):\n",
    "\tcolumns = X.columns.to_list()\n",
    "\tnorth_cities = {\"Delhi\", \"Kolkata\", \"Mumbai\", \"New Delhi\"}\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"{col}_is_north\": X.loc[:, col].isin(north_cities).astype(int)\n",
    "\t\t\tfor col in columns\n",
    "\t\t})\n",
    "\t\t.drop(columns=columns)\n",
    "\t)\n",
    "\n",
    "\n",
    "location_union_transformer = FeatureUnion(transformer_list=[\n",
    "\t(\"location_transformer\", location_transformer),\n",
    "\t(\"is_north_transformer\", FunctionTransformer(func=is_north))\n",
    "])\n",
    "\n",
    "time_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('dt', DatetimeFeatures(features_to_extract=['hour', 'minute'])),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "def part_of_day(X, start=0 , mid=8, end=16):\n",
    "    columns = X.columns.to_list()\n",
    "    X_temp = X.assign(\n",
    "        **{\n",
    "            col: pd.to_datetime(X.loc[:, col]).dt.hour\n",
    "            for col in columns\n",
    "        }\n",
    "    )\n",
    "    return (\n",
    "        X_temp\n",
    "        .assign(\n",
    "            **{\n",
    "                f'{col}_part_of_day': np.select(\n",
    "                    [\n",
    "                        X_temp.loc[:, col].between(start, mid, inclusive='left'),\n",
    "                        X_temp.loc[:, col].between(mid, end, inclusive='left')\n",
    "                    ], choicelist = ['start', 'mid'] ,default = 'end'\n",
    "                )\n",
    "                for col in columns\n",
    "            }\n",
    "        ).drop(columns=columns)\n",
    "    )\n",
    "\n",
    "part_of_day_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('part_of_day_func', FunctionTransformer(func=part_of_day)),\n",
    "        ('count_fre_encoder', CountFrequencyEncoder()),\n",
    "        ('min_max_scaler', MinMaxScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "time_union_transformer = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('time_transformer', time_transformer),\n",
    "        ('part_of_day_transformer', part_of_day_transformer)\n",
    "    ]\n",
    ")\n",
    "\n",
    "duration_log_transformer = FunctionTransformer(func=np.log)\n",
    "\n",
    "def is_direct_flight(X):\n",
    "    return X.assign(\n",
    "        is_direct_flight = X.total_stops.eq(0).astype(int)\n",
    "    )\n",
    "\n",
    "total_stops_transformer = FunctionTransformer(func=is_direct_flight)\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('airline_transformer', airline_transformer, ['airline']),\n",
    "    ('date_transformer', date_tranformer, ['date_of_journey']),\n",
    "    ('location_union_transformer', location_union_transformer, ['source', 'destination']),\n",
    "    ('time_union_transformer', time_union_transformer, ['dep_time', 'arrival_time']),\n",
    "    ('duration_log_transformer', duration_log_transformer, ['duration_minute']),\n",
    "    ('total_stops_trasformer', total_stops_transformer, ['total_stops'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf52ec0-caa2-4186-8a79-033229da50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['dep_time'] = pd.to_datetime(X_train['dep_time'].astype(str), format='%H:%M:%S')\n",
    "X_train['arrival_time'] = pd.to_datetime(X_train['arrival_time'].astype(str), format='%H:%M:%S')\n",
    "\n",
    "X_val['dep_time'] = pd.to_datetime(X_val['dep_time'].astype(str), format='%H:%M:%S')\n",
    "X_val['arrival_time'] = pd.to_datetime(X_val['arrival_time'].astype(str), format='%H:%M:%S')\n",
    "\n",
    "X_test['dep_time'] = pd.to_datetime(X_test['dep_time'].astype(str), format='%H:%M:%S')\n",
    "X_test['arrival_time'] = pd.to_datetime(X_test['arrival_time'].astype(str), format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d396adb7-a945-4ca3-9fb9-cb5793f9ab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1674 entries, 494 to 10080\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   airline          1674 non-null   object        \n",
      " 1   date_of_journey  1674 non-null   datetime64[ns]\n",
      " 2   source           1674 non-null   object        \n",
      " 3   destination      1674 non-null   object        \n",
      " 4   dep_time         1674 non-null   datetime64[ns]\n",
      " 5   arrival_time     1674 non-null   datetime64[ns]\n",
      " 6   total_stops      1674 non-null   int64         \n",
      " 7   additional_info  1674 non-null   object        \n",
      " 8   duration_minute  1674 non-null   int64         \n",
      "dtypes: datetime64[ns](3), int64(2), object(4)\n",
      "memory usage: 130.8+ KB\n"
     ]
    }
   ],
   "source": [
    "X_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "343f9e49-3ed7-4f1e-98f3-c7a892af1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(), SVR(),  KNeighborsRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), GradientBoostingRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c84882f2-53a5-4d6d-b266-4232661cb83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: LinearRegression()\n",
      "R^2: 0.5728\n",
      "Adjusted R^2: 0.5705\n",
      "RMSE: 3044.2407\n",
      "=============================\n",
      "Model Name: SVR()\n",
      "R^2: 0.0520\n",
      "Adjusted R^2: 0.0469\n",
      "RMSE: 4534.6868\n",
      "=============================\n",
      "Model Name: KNeighborsRegressor()\n",
      "R^2: 0.6126\n",
      "Adjusted R^2: 0.6106\n",
      "RMSE: 2898.7150\n",
      "=============================\n",
      "Model Name: DecisionTreeRegressor()\n",
      "R^2: 0.6634\n",
      "Adjusted R^2: 0.6616\n",
      "RMSE: 2701.9897\n",
      "=============================\n",
      "Model Name: RandomForestRegressor()\n",
      "R^2: 0.7961\n",
      "Adjusted R^2: 0.7950\n",
      "RMSE: 2102.9392\n",
      "=============================\n",
      "Model Name: GradientBoostingRegressor()\n",
      "R^2: 0.7757\n",
      "Adjusted R^2: 0.7745\n",
      "RMSE: 2205.8532\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', column_transformer),  # ColumnTransformer\n",
    "    ('model', model)  # RandomForestRegressor\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(f'Model Name: {model}')\n",
    "    get_metrics(pipeline, X_val, y_val)\n",
    "    print('=============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6422bff-7609-4a2a-8640-ca7c6acc9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', column_transformer),\n",
    "    ('RandomForestRegressor', RandomForestRegressor(max_depth=20, max_features=0.5, n_estimators=150))  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a806b51a-c801-4281-94d1-b900fb840bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Train DATASET==========\n",
      "R^2: 0.9522\n",
      "Adjusted R^2: 0.9522\n",
      "RMSE: 1014.7369\n",
      "\n",
      "==========VALIDATION DATASET==========\n",
      "R^2: 0.8060\n",
      "Adjusted R^2: 0.8049\n",
      "RMSE: 2051.5594\n",
      "\n",
      "==========TEST DATASET==========\n",
      "R^2: 0.8008\n",
      "Adjusted R^2: 0.8000\n",
      "RMSE: 2025.2181\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print()\n",
    "print('==========Train DATASET==========')\n",
    "get_metrics(pipeline, X_train, y_train)\n",
    "\n",
    "print()\n",
    "print('==========VALIDATION DATASET==========')\n",
    "get_metrics(pipeline, X_val, y_val)\n",
    "\n",
    "print()\n",
    "print('==========TEST DATASET==========')\n",
    "get_metrics(pipeline, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
